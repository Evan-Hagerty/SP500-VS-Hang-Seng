{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **S&P Vs Hang Seng**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Research Question**\n",
    "\n",
    "I will be using the year to date data from the Hang Seng(Hong Kong stock index) and the S&P500(United states stock index). Looking simply at their relationship based on daily percentage change.\n",
    "My null hypothesis is the Hang Seng and S&P 500 have statistically significant mean daily change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports to run code\n",
    "import pandas as pd \n",
    "import pandas_datareader as web\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using date time to mark starting and ending period for data frame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starting and ending dates using only this year because the S&P 500 changed in January 2021\n",
    "start = datetime(2021,1,2)\n",
    "end = datetime.today() \n",
    "sp500 =[]\n",
    "hang_seng =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sp and hang seng declared as variables\n",
    "stock1 = [\"^GSPC\"]\n",
    "stock2 = [\"^HSI\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Importing Data**\n",
    "\n",
    "Importing year to date data on both indexes using yahoo finance.\n",
    "This is the year to date data on the S&P 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RemoteDataError",
     "evalue": "No data fetched using 'YahooDailyReader'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteDataError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-1812446ed168>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#getting data from yahoo and creating dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_sp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstock1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"yahoo\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf_sp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_sp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas_datareader\\data.py\u001b[0m in \u001b[0;36mDataReader\u001b[1;34m(name, data_source, start, end, retry_count, pause, session, api_key)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdata_source\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"yahoo\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m         return YahooDailyReader(\n\u001b[0m\u001b[0;32m    377\u001b[0m             \u001b[0msymbols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas_datareader\\base.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    256\u001b[0m             \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dl_mult_symbols\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msymbols\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m             \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dl_mult_symbols\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msymbols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas_datareader\\base.py\u001b[0m in \u001b[0;36m_dl_mult_symbols\u001b[1;34m(self, symbols)\u001b[0m\n\u001b[0;32m    275\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpassed\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"No data fetched using {0!r}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRemoteDataError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    278\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstocks\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfailed\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpassed\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRemoteDataError\u001b[0m: No data fetched using 'YahooDailyReader'"
     ]
    }
   ],
   "source": [
    "#getting data from yahoo and creating dataframe\n",
    "df_sp = web.DataReader(stock1,\"yahoo\",start,end)\n",
    "df_sp = df_sp.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting data from yahoo and creating dataframe\n",
    "df_hs = web.DataReader(stock2, \"yahoo\",start,end)\n",
    "df_hs = df_hs.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3)Cleaning data**\n",
    "\n",
    "Read the data frames into a csv file to make the information more readable.\n",
    "I got rid of the useless column and added a new row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading data into a csv file\n",
    "df_sp.to_csv('sp500.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning data to make more readable\n",
    "pc_sp = pd.read_csv('sp500.csv')\n",
    "pc_sp = pc_sp.drop(pc_sp.index[0])\n",
    "top_row = pd.DataFrame({'Date':[''],'Adj Close':['S&P 500'],'Close':['S&P 500'],'High':['S&P 500'],'Low':['S&P 500'],'Open':['S&P 500'],'Volume':['S&P 500']})\n",
    "pc_sp = pd.concat([top_row, pc_sp]).reset_index(drop = True)\n",
    "pc_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading data into a csv file \n",
    "df_hs.to_csv('hang_seng.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning data to make more readable\n",
    "pc_hs = pd.read_csv('hang_seng.csv')\n",
    "pc_hs = pc_hs.drop(pc_hs.index[0])\n",
    "top_row = pd.DataFrame({'Date':[''],'Adj Close':['Hang Seng'],'Close':['Hang Seng'],'High':['Hang Seng'],'Low':['Hang Seng'],'Open':['Hang Seng'],'Volume':['Hang Seng']})\n",
    "pc_hs = pd.concat([top_row, pc_hs]).reset_index(drop = True)\n",
    "pc_hs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) Data Visualization**\n",
    "\n",
    "Scatter plots to show each data point for the year to date of the S&P 500 and the Hang Seng. This is simply to show all the data charted as individual points in time and price. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sp500[\"Adj Close\"] price YTD\n",
    "plt.figure(figsize=(11,4))\n",
    "\n",
    "y_sp= df_sp[\"Adj Close\"]\n",
    "x_sp = df_sp[\"Date\"]\n",
    "x = plt.gca().xaxis\n",
    "\n",
    "# rotate the tick labels for the x axis\n",
    "for item in x.get_ticklabels():\n",
    "    item.set_rotation(45)\n",
    "\n",
    "\n",
    "plt.title('S&P 500', size = 40)\n",
    "plt.xlabel('Date', size = 20)\n",
    "plt.ylabel('Price', size = 20)\n",
    "plt.scatter(x_sp, y_sp, c='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hang seng[\"Adj Close\"] price YTD\n",
    "plt.figure(figsize=(11,4))\n",
    "\n",
    "y_hs=df_hs[\"Adj Close\"]\n",
    "x_hs=df_hs[\"Date\"]\n",
    "x = plt.gca().xaxis\n",
    "\n",
    "# rotate the tick labels for the x axis\n",
    "for item in x.get_ticklabels():\n",
    "    item.set_rotation(45)\n",
    "\n",
    "plt.title('Hang Seng', size = 40)\n",
    "plt.xlabel('Date', size = 20)\n",
    "plt.ylabel('Price', size = 20)\n",
    "plt.scatter(x_hs, y_hs, c='red',)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) Data Vizualisation**\n",
    "\n",
    "Created line plots of the year to date data of the S&P 500 and the Hang Seng to show trend lines for both indexes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple line chart or S&P 500 is price action\n",
    "plt.figure(figsize= (12,2.8))\n",
    "\n",
    "plt.plot(x_sp, y_sp, label= \"S&P 500 Index\",c='blue', linestyle=\"-.\")\n",
    "\n",
    "x = plt.gca().xaxis\n",
    "\n",
    "# rotate the tick labels for the x axis\n",
    "for item in x.get_ticklabels():\n",
    "    item.set_rotation(45)\n",
    "plt.legend(['S&P500'], prop={'size': 20})\n",
    "plt.xlabel('Date', size = 18)\n",
    "plt.ylabel('Price', size = 18)\n",
    "plt.show()\n",
    "#simple line charting the Hang Seng price action\n",
    "plt.figure(figsize= (12,2.8))\n",
    "plt.plot(x_hs, y_hs, label= \"Hang Seng Index\",c='red', linestyle=\":\")\n",
    "\n",
    "x = plt.gca().xaxis\n",
    "\n",
    "# rotate the tick labels for the x axis\n",
    "for item in x.get_ticklabels():\n",
    "    item.set_rotation(45)\n",
    "plt.legend(['Hang Seng'], prop={'size': 20})\n",
    "plt.xlabel('Date', size = 18)\n",
    "plt.ylabel('Price', size = 18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5) A Model**\n",
    "\n",
    "Plotting the daily change percentage to be used in our t-test. showing the plot gives a general idea of why we wil get the p-value we recieve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#percentage change to give an even metric for t-test \n",
    "plt.figure(figsize=(14,6))\n",
    "a = ((df_hs[\"Close\"]- df_hs[\"Open\"])/(df_hs[\"Open\"]))*100\n",
    "b = ((df_sp[\"Close\"]- df_sp[\"Open\"])/(df_sp[\"Open\"]))*100\n",
    "plt.xlabel('Date', size =20)\n",
    "plt.ylabel('Daily Percentage change YTD', size = 15)\n",
    "\n",
    "x = plt.gca().xaxis\n",
    "\n",
    "# rotate the tick labels for the x axis\n",
    "for item in x.get_ticklabels():\n",
    "    item.set_rotation(45)\n",
    "\n",
    "\n",
    "plt.plot(x_hs, a, c='red', linestyle=\":\")\n",
    "plt.plot(x_sp, b, c='blue', linestyle=\"-.\")\n",
    "#legend to show which represents which data\n",
    "plt.legend(['Hang Seng','S&P 500'], prop={'size': 20})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5) A Model**\n",
    "\n",
    "Running an paired t-test to get our p-value. We will be using the paired T-test, because both samples are related. If the p-value is greater than .05 then we will confirm our null hypothesis that the mean percentage of daily change year to date of the S&P 500 and the Hang Seng show statistical significance. If the p-value is less than .05 then we will reject our null hypothesis that the mean percentage of daily change year to date are statistically significant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tStat, pValue =  stats.ttest_rel(a, b)\n",
    "print(\"P-Value:{0} T-Statistic:{1}\".format(pValue,tStat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at our p-value it is clear that we must accept our null hypothesis.\n",
    "Our p-value shows that these two sample sets show statistically signicant correlation. By using the mean daily change percentage we are able to see this on a percentage basis that allows us to access both samples equitably. Our next step would be to extend our time horizon and again run the same t-test to see if this is just for the year to date samples. If we can show further historical statistically significant correlation it would merit further inspection. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
